# -*- coding: utf-8 -*-
"""Dreaddit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GmNz7sBSOg8VHovCCznJEUtGLFjWzXm2
"""

import pandas as pd
import numpy as np
from wordcloud import STOPWORDS
from PIL import Image
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import warnings
warnings.filterwarnings("ignore")

df1=pd.read_csv("dreaddit-train.csv")
df1.head()

df1. describe()

df1.isnull().sum()

df1.info()

df2=pd.read_csv("dreaddit-test.csv")
df2.head()

df2.info()

df2.isnull().sum()

df1.columns

df2.columns

from textblob import TextBlob

TextBlob("the best").polarity #We find the positive or negative of the words.

TextBlob("the best").sentiment

def detect_sentiment(text):
    return TextBlob(text).sentiment.polarity

df3=df1[["text"]]

df3.head()

df3["sentiment"]=df3["text"].apply(detect_sentiment)

df3.head()

df3.sentiment.value_counts()

import nltk
import re
stemmer = nltk.SnowballStemmer("english")
from nltk.corpus import stopwords
import string

def wc(data,bgcolor):
    plt.figure(figsize=(20,20))
    mask=np.array(Image.open('/kaggle/input/stressanalysisinsocialmedia/stress-954814_960_720.png'))
    wc=WordCloud(background_color=bgcolor,stopwords=STOPWORDS,mask=mask)
    wc.generate(' '.join(data))
    plt.imshow(wc)
    plt.axis("off")

df3["label"]=df1["label"].map({0: "No Stress", 1: "Stress"})
df3=df3[["text", "label"]]

df3.head()

import seaborn as sns

sns.countplot(x=df3.label)